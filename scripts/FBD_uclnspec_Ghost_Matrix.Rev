clear();
#working_directory <- getwd()+"/Documents/RevBayes_Projects";
#setwd(working_directory);

################################################################################
#
# RevBayes script: A (no longer so) simple FBD analysis
#
# This file: Runs the full MCMC ...
#
# authors: Tracy A. Heath, Josh Justison, JoÃ«lle Barido-Sottani, and Walker Pett
# monkeyed with by: April Wright & Peter Wagner
#
################################################################################
punctuated <- TRUE;


#######################
# Reading in the Data #
#######################
# Read the full list of taxa (including all fossils and extant species #
taxa <- readTaxonData("data/Simulated_Fossil_Intervals_Tue_Sep_13_14-03-55_2022.tsv")

# Import the morphological character matrix #
morpho <- readDiscreteCharacterData("data/Simulated_Character_Data_2_StatesTue_Sep_13_14-03-55_2022.nex")

## helpers
otus <- taxa.size();
n_taxa <- taxa.size();
moves = VectorMoves();
num_branches <- 2 * n_taxa - 2;

print("processed data");

##########################################################################################
# Joint Fossilized Birth-Death Process prior on the topology and fossil occurrence times #
##########################################################################################
# set up skyline origination & extinction rates
max_max_age <- taxa[1].getMaxAge();
for (i in 2:otus) if (max_max_age < taxa[i].getMaxAge())   max_max_age <- taxa[i].getMaxAge();
if (round(max_max_age)<max_max_age) {
  max_max_age <- 1+round(max_max_age);
  } else {
  max_max_age <- round(max_max_age);
  }
for (i in 1:(2*max_max_age))  timeline[i] <- i;

nbins <- abs(timeline.size());
for (i in 1:nbins)  {
  if (i==1)   {
    bin_durations[i] <- timeline[i];
    } else   {
    bin_durations[i] <- timeline[i]-timeline[i-1];
    }
  }
bin_durations <- append(bin_durations,10);

sampling <- rep(1,nbins+1);
# Define exponential priors on the birth rate and death rate #
for (i in 1:(nbins+1)) {
# print(i);
 speciation_rate[i] ~ dnExponential(1/sqrt(2));
#  speciation_rate[i] ~ dnExponential(10);

 # Specify a scale move on the speciation_rate parameter #
 moves.append(mvScale(speciation_rate[i], lambda=0.01, weight=5));
 moves.append(mvScale(speciation_rate[i], lambda=0.10, weight=3));
 moves.append(mvScale(speciation_rate[i], lambda=1.00, weight=1));


# turnover[i] ~ dnLognormal(sqrt(0.5), 2);
# moves.append(mvSlide(turnover[i], delta=0.01, weight=5));
# moves.append(mvSlide(turnover[i], delta=0.10, weight=3));
# moves.append(mvSlide(turnover[i], delta=1.00, weight=1));

 extinction_volatility[i] ~ dnNormal(0,1);
 moves.append(mvSlide(extinction_volatility[i], delta=0.01, weight=5));
 moves.append(mvSlide(extinction_volatility[i], delta=0.10, weight=3));
 moves.append(mvSlide(extinction_volatility[i], delta=1.00, weight=1));

# setup extinction rate relative to speciation rate.
 extinction_rate[i] := abs(speciation_rate[i]*sqrt(0.5)*(2^extinction_volatility[i]));
 turnover[i] := abs(sqrt(0.5)*(2^extinction_volatility[i]));
 # Specify a scale move on the turnover parameter #

 # Assume an exponential prior on the rate of sampling fossils (psi) #
 psi[i] ~ dnExponential(sampling[i]);
 # Specify a scale move on the psi parameter #
 moves.append(mvScale(psi[i], lambda=0.01, weight=5));
 moves.append(mvScale(psi[i], lambda=0.10, weight=3));
 moves.append(mvScale(psi[i], lambda=1.00, weight=1));
 moves.append(mvSlide(psi[i], delta=1.00, weight=1));

 } # end skyline loops

# Create deterministic nodes for the diversification and turnover rates so that they can be monitored #
#extinction_rate := turnover*speciation_rate;
diversification := speciation_rate - extinction_rate

# Fix the probability of sampling parameter (rho) to 1, #
rho <- 0.00;

# The FBD is conditioned on a starting time for the process, which is the origin time #
# Specify a uniform prior on the origin #
origin_time ~ dnUnif(max_max_age,max_max_age*2);

# Specify a sliding-window move on the origin_time parameter #
# This move will be applied with 3 different window widths (delta) to help improve mixing #
moves.append(mvSlide(origin_time, weight=1.0));

### Define the tree-prior distribution as the fossilized birth-death process ###
fbd_tree ~ dnFBDP(origin=origin_time, lambda=speciation_rate, mu=extinction_rate, psi=psi, rho=rho, taxa=taxa, timeline=timeline);
# Specify moves on the tree and node times #
moves.append(mvFNPR(fbd_tree, weight=15.0));
moves.append(mvCollapseExpandFossilBranch(fbd_tree, origin_time, weight=6.0))

# These moves update the node ages #
moves.append(mvNodeTimeSlideUniform(fbd_tree, weight=40.0))
# Because we are conditioning on the origin time, we must also sample the root node age #
moves.append(mvRootTimeSlideUniform(fbd_tree, origin_time, weight=5.0))

### Use stratigraphic range data to explicitly sample the fossil occurence times ###
# Use a for loop to create a uniform distribution on the occurence time for each fossil #
# The boundaries of the uniform distribution are specified in the tsv file #
fossils = fbd_tree.getFossils();
for(i in 1:fossils.size())  {
#  fossils[i]
  t[i] := tmrca(fbd_tree, clade(fossils[i]))

  a_i = fossils[i].getMinAge()
  b_i = fossils[i].getMaxAge()

  F[i] ~ dnUniform(t[i] - b_i, t[i] - a_i)
  F[i].clamp(0)
}

# We assume a strict morphological clock rate, drawn from an exponential prior #
#clock_morpho ~ dnExponential(1.0)
#moves.append(mvScale(clock_morpho, weight=4.0))

ucln_mean ~ dnExponential(2.0)
### we will also estimate the standard deviation of the lognormal (ucln_sigma) with an exponential hyperprior
ucln_sigma ~ dnExponential(3.0)
### we can create deterministic nodes for the variance and mu of the lognormal
ucln_var := ucln_sigma * ucln_sigma
ucln_mu := ln(ucln_mean) - (ucln_var * 0.5)
### both the ucln_mean and ucln_sigma will be operated on by scale moves
moves.append(mvScale(ucln_mean, lambda=1.0, tune=true, weight=4.0))
moves.append(mvScale(ucln_sigma, lambda=0.5, tune=true, weight=4.0))


# Add a move to sample the fossil times #
moves.append(mvFossilTimeSlideUniform(fbd_tree, origin_time, weight=5.0))
print("processed FBD");

#Set up Gamma-distributed rate variation.
alpha_morpho ~ dnExponential(1.0)
rates_morpho := fnDiscretizeGamma(alpha_morpho, alpha_morpho, 4)

#Moves on the parameters to the Gamma distribution.
moves.append(mvScale(alpha_morpho, weight=5.0))



num_samp_anc := fbd_tree.numSampledAncestors();
if (punctuated) {
  pr_pe <- 1; # probability of cladogenesis per divergence; = 1.0 for pure PE model; minimum of 0.5 for mixed gradual + PE
  for (bn in 1:num_branches) {
    branch_lengths[bn]:=fbd_tree.branchLength(bn);               # this is branch *duration* not expected change!

    divergence_dates[bn]:=fbd_tree.nodeAge(bn);                   # this is when a hypothesized ancestor diverges or an OTU is first seen;
    # get the bin ("stage", etc.) in which lineage diverges/gives rise to OTU
    divergence_bin[bn]:=ceil(fbd_tree.nodeAge(bn));
    # get the time between divergence/appearance & end of bin/stage/etc.
    divergence_offset[bn]:=abs((timeline[divergence_bin[bn]]-bin_durations[divergence_bin[bn]])-divergence_dates[bn]);

    origin_dates[bn]:=fbd_tree.branchLength(bn)+fbd_tree.nodeAge(bn); # this is when a lineage diverged from its ancestor
    # get the bin ("stage", etc.) in which lineage diverged from rest of clade
    origin_bin[bn]:=ceil(origin_dates[bn]);
    # get the time between onset of origin bin & divergence of lineage from rest of tree
    origin_offset[bn]:=timeline[origin_bin[bn]]-origin_dates[bn];

    # "synoptic" range of ghost taxon/lineage within tree
    bin_span[bn]:=abs(origin_bin[bn]:divergence_bin[bn]);
    ttl_bins[bn]:=abs(bin_span[bn].size());
    a[bn]:=rep(0,divergence_bin[bn]-1);
    rn[bn]:=rep(1,ttl_bins[bn]);
    z[bn]:=rep(0,(nbins+1-origin_bin[bn]));
    ghost_taxon[bn] := append(append(a[bn],rn[bn]),z[bn]);
    local_branch_rates[bn] ~ dnLnorm(ucln_mu, ucln_sigma);
    moves.append(mvScale(local_branch_rates[bn],lambda=1.0,tune=true,weight=2.0));
    exp_branchings[bn] := abs(pr_pe + sum(ghost_taxon[bn]*(speciation_rate*bin_durations))-(origin_offset[bn]*speciation_rate[origin_bin[bn]]+divergence_offset[bn]*speciation_rate[divergence_bin[bn]]));
    branch_rates[bn] := abs(local_branch_rates[bn]*exp_branchings[bn]);
    exp_subsequent_branches[bn] :=(sum(ghost_taxon[bn]*(speciation_rate*bin_durations))-(((origin_offset[bn]*speciation_rate[origin_bin[bn]])+(divergence_offset[bn]*speciation_rate[divergence_bin[bn]]))))
    exp_speciations_per_myr[bn] :=(fbd_tree.branchLength(bn)+exp_subsequent_branches[bn])/fbd_tree.branchLength(bn)
    ave_speciation_rate[bn] := (sum(ghost_taxon[bn]*(speciation_rate*bin_durations))-(((origin_offset[bn]*speciation_rate[origin_bin[bn]])+(divergence_offset[bn]*speciation_rate[divergence_bin[bn]]))))/fbd_tree.branchLength(bn);          #    exp_subsequent_branches[bn]:=(sum(ghost_taxon[bn]*(speciation_rate*bin_durations))-(((origin_offset[bn]*speciation_rate[origin_bin[bn]])+(divergence_offset[bn]*speciation_rate[divergence_bin[bn]]))))
    exp_speciations_per_myr[bn] := (fbd_tree.branchLength(bn)+exp_subsequent_branches[bn])/fbd_tree.branchLength(bn)
    ave_speciation_rate[bn] := (sum(ghost_taxon[bn]*(speciation_rate*bin_durations))-(((origin_offset[bn]*speciation_rate[origin_bin[bn]])+(divergence_offset[bn]*speciation_rate[divergence_bin[bn]]))))/fbd_tree.branchLength(bn);
    alpha_forward[bn] := exp_speciations_per_myr[bn]*(1+ave_speciation_rate[bn])
    alpha_forward[bn]
    pi_prior := v(abs(alpha_forward[bn]), abs(alpha_forward[bn]))

      pi[bn] ~ dnDirichlet(pi_prior)
      freq_zero[bn] := pi[bn][1]
      freq_one[bn]  := pi[bn][2]
      sp <- simplex(freq_zero[bn], freq_one[bn])
      moves.append( mvBetaSimplex(pi[bn], alpha=10, weight=4.0) )
        # now also set up the opposite rate matrix
      Q_morpho[bn] := fnFreeK(sp)
  }
  } else {
  exp_branchings = rep(1,num_branches);
  }

### now we will create a vector of stochastic nodes
### each element in the vector represents a branch rate
### the indices of the vector correspond to branch indices in the tree
### using a for-lop initialize the branch rates and assign a move to each one


### add 2 more moves on the *local* branch rate vector
moves.append(mvVectorScale(local_branch_rates,lambda=1.0,tune=true,weight=2.0))
moves.append(mvVectorSingleElementScale(local_branch_rates,lambda=30.0,tune=true,weight=1.0))

### a helpful parameter to monitor
mean_rt := mean(branch_rates);
root_state <- simplex(alpha_forward[1],alpha_forward[1])

phyMorpho ~ dnPhyloCTMC(tree=fbd_tree, siteRates=rates_morpho, branchRates=branch_rates, Q=Q_morpho, type="Standard", coding="variable", rootFrequencies = root_state)
phyMorpho.clamp(morpho);

### Create the substitution model and clamp with our observed Standard data ###
# Here we use the option siteMatrices=true specify that the vector Q #
# represents a site-specific mixture of rate matrices #
# We also condition on observing only variable characters using coding="variable" #


########
# MCMC #
########

# initialize the model object #
mymodel = model(fbd_tree);

monitors = VectorMonitors()

# Create a vector of monitors #
output_file1 <- "output/Simulated_" + "moves" + "_Dated.log";
output_file2 <- "output/Simulated_" + "moves" + "_Dated.tre";

# 1. for the full model #
monitors.append(mnModel(filename=output_file1, printgen=100, exclude = ["F"]));

# 2. the tree #
monitors.append(mnFile(filename=output_file2, printgen=100, fbd_tree));

# 3. and a few select parameters to be printed to the screen #
monitors.append(mnScreen(printgen=10, speciation_rate))

# Initialize the MCMC object #
mymcmc = mcmc(mymodel, monitors, moves)

# Run the MCMC #
mymcmc.run(generations=10000000)

# Quit RevBayes #
q()
